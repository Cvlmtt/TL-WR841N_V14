# Implementation of the C2 Botnet
At this stage of the research, we shifted our focus toward the design and implementation of a command-and-control (C2) 
botnet architecture capable of leveraging consumer-grade embedded devices, specifically the TP-Link TL-WR841N router 
family as client nodes. While the experimental setup relied on a single physical hardware device as a representative
sample, the architectural design and implementation choices were made with the assumption that multiple homogeneous 
devices could participate in the same network.

The role of the C2 server was fulfilled by standard desktop systems under the researchers’ control. This separation
allowed us to isolate the embedded client constraints from the server-side logic and to evaluate how resource-limited
devices behave when integrated into a coordinated remote-control infrastructure. 
The resulting system serves as a controlled research artifact rather than a production-grade or malicious deployment.

## Research Objectives and Context
The primary objective of this phase was to demonstrate the feasibility of integrating embedded consumer routers into
a centralized command-and-control framework. The focus was not on maximizing stealth, scale, or offensive capabilities,
but rather on validating that such devices can reliably establish outbound connectivity, maintain persistent 
communication channels, and respond to remote instructions under realistic firmware constraints.

All activities were conducted strictly within an academic and experimental context. The botnet implementation was 
developed to support security research, firmware analysis, and defensive understanding of real-world threats affecting
embedded systems. No uncontrolled deployment, third-party targeting, or malicious usage was involved at any stage of 
the study.

A secondary objective was to provide a simple and easily reproducible design. By deliberately avoiding unnecessary 
complexity, the implementation aims to remain accessible to researchers and students interested in embedded security, 
malware analysis, and networked systems. This simplicity also facilitates code review, debugging, and systematic 
evaluation of design trade-offs inherent to constrained environments.

## Overview of the Botnet Architecture
The adopted architecture follows a classical centralized command-and-control (C2) model. In this design, a single 
authoritative server coordinates a set of distributed client nodes, each of which initiates and maintains communication
with the server. This approach was chosen for its conceptual clarity and its prevalence in both legitimate 
remote-management systems and real-world botnets.

From an architectural standpoint, the C2 server acts as a coordination hub, responsible for client registration, 
command distribution, and liveness monitoring. Embedded devices operate exclusively as clients, initiating outbound 
connections to the server and awaiting instructions. This asymmetry reflects typical deployment scenarios for 
embedded malware, where inbound connectivity to the device may be restricted by network address translation (NAT), 
firewall rules, or ISP-level filtering.

The architecture deliberately avoids peer-to-peer communication or decentralized control mechanisms. While such 
approaches offer advantages in resilience and scalability, they introduce additional complexity that falls outside 
the scope of this research. Instead, the centralized model provides a clear and analyzable framework for studying 
communication reliability, persistence, and control in resource-constrained embedded platforms.

Overall, this architectural choice enables a controlled exploration of botnet behavior while maintaining a clear 
separation between experimental objectives and real-world threat operationalization.

## Client–Server Communication Model
Communication between the embedded clients and the command-and-control server is implemented through direct 
socket-based interactions. The overall model follows a client-initiated paradigm, in which each embedded device 
actively establishes a connection to the server rather than passively awaiting inbound requests. 
This design choice reflects common network constraints in residential and embedded deployments, such as network 
address translation (NAT) and firewall restrictions, which often prevent unsolicited inbound connections.

Upon startup, the client initiates a TCP connection to a predefined server endpoint. This initial connection serves 
as the primary command channel, over which control messages, commands, and responses are exchanged. Once the 
connection is established, a lightweight handshake phase is performed to identify the client instance and negotiate
auxiliary communication parameters. This negotiation includes the dynamic allocation of a secondary communication 
channel used for liveness monitoring.

Message exchanges follow a deliberately simple, text-oriented structure derived directly from the client implementation.
Messages are composed of clearly delimited fields separated by fixed characters, allowing for straightforward parsing
without the need for complex serialization libraries that may be unavailable or impractical in constrained 
environments. Control messages include command identifiers, optional parameters, and payload data when required, 
while responses consist of raw command output or acknowledgment strings.

In addition to the primary TCP command channel, a secondary UDP-based communication path is used for heartbeat 
signaling. This separation of concerns allows the system to distinguish between control-plane activity and 
liveness monitoring, reducing coupling between command execution and connectivity supervision. The client periodically
listens for heartbeat messages and updates its internal state based on their reception, enabling timely detection of
server unavailability or network disruption.

Overall, the communication model prioritizes reliability, simplicity, and compatibility with limited embedded runtimes. 
Rather than optimizing for throughput or encryption, the implementation emphasizes predictable behavior and ease of 
analysis, which are essential characteristics in an academic research context.

## Design Choices for Embedded Environments
Designing a reliable client for the target hardware required careful consideration of the limitations imposed by the 
underlying software stack, most notably the legacy Linux 2.6.x kernel and the use of the uClibc standard C library.
These components significantly constrain the availability and behavior of common system calls, particularly in the area
of networking and signal handling.

Several socket-related features commonly available on modern systems either behave inconsistently or are entirely 
unsupported in this environment. For example, certain socket options and timeout mechanisms that are typically used to 
prevent blocking behavior were found to be unreliable or non-functional when combined with uClibc. As a result, the 
implementation avoids reliance on receive and send timeouts at the socket level, instead favoring explicit multiplexing 
through `select()` and `poll()` to maintain control over blocking semantics.

The interaction between the older kernel and uClibc also introduces subtle edge cases in connection handling. 
Non-blocking I/O, while supported, may produce unexpected error codes or incomplete state transitions under load or 
during reconnection attempts. These issues are addressed in the client code through conservative error checking, 
repeated validation of return values, and explicit cleanup of socket state before reuse. In particular, reconnection 
logic is designed to fully tear down and recreate sockets rather than attempting to recover partially failed connections.

Signal handling represents another area where the embedded environment imposes constraints. Certain signals may not be 
delivered or handled consistently, especially when combined with daemonized processes and network I/O. The client 
therefore adopts a minimal and defensive signal-handling strategy, explicitly ignoring or trapping only a small subset 
of signals to ensure continued execution without relying on complex inter-process coordination.

Finally, limitations in system resources, such as memory availability, file descriptor limits, and the absence of 
advanced debugging facilities, necessitated a design that minimizes dynamic allocation and avoids deep call stacks. 
Buffer sizes are fixed and conservative, and protocol parsing is implemented using straightforward string and memory 
operations to reduce the likelihood of undefined behavior.

Taken together, these design choices reflect a pragmatic adaptation to an aging and constrained execution environment. 
Rather than attempting to replicate modern networking abstractions, the implementation embraces a 
lowest-common-denominator approach that prioritizes stability and predictability over feature richness, 
aligning with the goals of controlled experimentation and firmware-level analysis.

## Analysis of Constraints (MIPS, uClibc, BusyBox)

The design and implementation of the botnet client were strongly influenced by the characteristics of the target 
execution environment, which consists of a MIPS-based embedded platform running a legacy Linux 2.6.x kernel, the uClibc
standard C library, and a BusyBox-based userland. Each of these components introduces specific constraints that 
collectively shape the feasibility and reliability of the resulting system.

From an architectural perspective, the MIPS processor imposes limitations related to instruction set support, endianness,
and toolchain availability. Cross-compilation is mandatory, and subtle assumptions commonly made in x86-oriented 
software, such as memory alignment, atomicity, or undefined behavior tolerance, must be explicitly avoided. 
These constraints encourage conservative coding practices and careful validation of system-call interactions.

The use of uClibc, rather than glibc, represents one of the most significant sources of complexity. While uClibc 
provides a largely POSIX-compatible interface, its implementation is intentionally minimal and, in older versions, 
incomplete. Several networking-related features exhibit behavior that differs from modern expectations, including 
partial or inconsistent support for socket options, limited reliability of timeout mechanisms, and reduced robustness 
in edge-case error handling. In particular, reliance on convenience abstractions such as socket-level receive timeouts 
or advanced polling mechanisms can lead to undefined or unstable behavior in this environment.

BusyBox further constrains the execution context by consolidating essential userland utilities into a single, 
compact binary. While this approach is well-suited to resource-limited devices, it restricts the availability of 
external tools and auxiliary binaries that might otherwise be used for diagnostics, scripting, or process management. 
As a result, any client-side logic must be largely self-contained and avoid dependencies on non-essential system utilities.

Taken together, these constraints necessitate a design philosophy centered on minimalism and predictability. Rather 
than attempting to emulate modern desktop or server environments, the implementation embraces the limitations of the 
platform, favoring explicit control over I/O, cautious error handling, and avoidance of rarely tested code paths. 
This constraint-driven approach not only improves stability but also provides valuable insight into how real-world 
embedded malware must adapt to similarly restrictive conditions.

## Design of the Bot Client

The bot client was designed as a long-lived, autonomous process capable of operating reliably within the constraints
outlined above. Its primary role is to establish and maintain communication with a central command-and-control server, 
execute received instructions, and report status information, all while minimizing its operational footprint on the host 
system.

A key design principle was resilience in the face of unreliable networking and limited system support. Rather than 
assuming continuous connectivity or ideal execution conditions, the client is structured around repeated connection
attempts, explicit state transitions, and conservative recovery mechanisms. All external interactions, particularly 
network operations, are treated as potentially transient, and failures are handled through controlled teardown and 
reinitialization rather than complex in-place recovery.

The client architecture is deliberately monolithic and event-driven. By consolidating functionality into a single 
process and relying on explicit I/O multiplexing, the design avoids the overhead and unpredictability associated with 
multi-threading or inter-process communication, which can be problematic on older kernels and embedded runtimes. 
This approach also simplifies reasoning about execution flow and resource usage.

Identity and session management are handled locally by the client, enabling it to present a consistent logical identity 
to the server across reconnections without relying on persistent storage or external configuration files. This choice 
reflects both the limited filesystem capabilities of the target platform and the desire to reduce observable artifacts 
on the device.

Finally, the client emphasizes transparency and debuggability within the constraints of the environment. Logging and 
status output are implemented in a restrained manner to avoid excessive resource consumption, while still providing 
sufficient visibility for experimental observation and troubleshooting. This balance allows the client to function as 
a research instrument, facilitating the study of embedded command-and-control behavior without introducing unnecessary 
complexity.

In summary, the bot client represents a pragmatic synthesis of functional requirements and environmental limitations. 
Its design prioritizes robustness, simplicity, and compatibility over performance or sophistication, aligning closely 
with the overarching goal of conducting controlled and reproducible academic research on embedded botnet architectures.


## Unique Node Identification (Client ID)

In order to manage distributed nodes in a more scalable and systematic way, each embedded client must generate and store
a local unique identifier. This identifier acts as a stable logical handle which helps the command-and-control server to 
differentiate between them, manage their statuses across multiple sessions, and selectively target them when issuing 
commands.

The identifier is created when the client runs, and is created by a mechanism which is simple and lightweight, so it can 
function in the embedded resource constrained execution environment, and produce a small alphanumeric identifier. Even 
though the specific mechanism in use is a detail of the implementation that is granted for the sake of reproducibility 
in the experiments, it is intended to produce a value that in expectation would be unique for the test network. 
This client-generated unique identifier is incorporated in the handshake process of the network protocol, which gives
the server the unique identifier as a permanent token for associating with the client, and managing the client’s state 
across any disconnections or reboots.


## Mechanism for Connecting to the C2 Server

The connection model designed by the client is proactive and resilient in the sense that he embedded device is designed 
to initiate outbound connections to the C2 server. This is a behavioral consequence of the client design and practical 
consideration such as NAT and firewall traversal, which are common in residential network environments.

The client tries to create a TCP socket and connect to a given server address as many times as possible. He tries to
establish a connection in a loop. Each connection attempt is separated by a time delay to manage reconnection behavior
which, in the positive or negative extreme, can destabilize the system, or clog the network. The failed attempts lead to 
a complete erasure of the socket state, which in turn guarantees that the next attempts are starting from a known clean
state.

After a connection has been established, the socket is the main control channel on which commands and responses are sent.
The client, by design, views this connection as temporary. He constantly checks the connection and resets it as soon as
a connection is lost or there is no activity. This approach prioritizes robustness and guarantees that the client does 
not run on undefined socket states which might lead to a partial failure.


## Persistence Management and Daemonization

Persistence on the target device is achieved through firmware modification rather than runtime exploitation or temporary 
persistence mechanisms. By embedding the botnet client directly into the firmware image and integrating it into the 
system initialization sequence, the client is guaranteed to execute automatically on every boot, including power 
cycles and factory resets that preserve firmware state.

The initialization process is orchestrated through modifications to the system’s init configuration, ensuring that the
botnet components are launched during the early stages of system startup. A dedicated initialization script is 
responsible for coordinating the startup sequence, including basic environment preparation, network availability checks,
and the concurrent launch of both the backdoor service and the C2 client process.

Daemonization is used to strangle the client from any controlling terminal to use it as a background service. This means
the process stays alive regardless of user logins, or interactive sessions which is a standard service behavior on embedded
Linux systems. Logging is redirected to local storage, so it can be used for post-mortem analysis, without interfering with the
standard stream system outputs.

All in all, the persistence is deterministic, with the emphasis on reliability and reproducibility, as opposed to 
obfuscation, which speaks to the research’s academic nature.


## Initial Handshake Protocol

Following the establishment of the primary TCP connection, the client initiates a handshake phase to synchronize state 
with the C2 server. This protocol serves multiple purposes: it announces the presence of a new client, conveys 
identifying information, and communicates auxiliary parameters required for subsequent interaction.

The handshake message includes structured fields that describe the client’s identity, software version, and 
communication capabilities. Among these parameters is the dynamically assigned port number used for secondary 
communication, allowing the server to associate multiple channels with a single logical client instance. The server
responds with an acknowledgment message, confirming successful registration and readiness to proceed.

This explicit handshake phase establishes a clear session boundary and ensures that both parties operate with a 
consistent view of the connection state before entering the main operational loop. By keeping the protocol simple and
text-based, the implementation avoids dependencies on complex parsing logic while remaining sufficiently expressive for
experimental needs.

## TCP Command Channel

The TCP command channel constitutes the primary control plane of the botnet architecture. All command messages issued 
by the server, as well as execution results generated by the client, are exchanged over this persistent connection. 
The client continuously monitors the socket for incoming data and processes commands sequentially as they arrive.

Commands are transmitted as plain-text strings, allowing the client to interpret them directly without additional 
decoding layers. Upon receipt of a command, the client executes it in the local execution context and captures the 
resulting output. This output is then streamed back to the server over the same channel, preserving ordering and 
simplifying correlation between commands and responses.

The use of a reliable, connection-oriented transport ensures that command delivery and response transmission occur in 
a predictable manner, which is particularly important in environments with limited debugging visibility.


## UDP Heartbeat Channel

In parallel with the TCP command channel, a secondary, unidirectional communication path is established for liveness 
monitoring. This channel employs the User Datagram Protocol (UDP) and operates on a distinct port, functionally
decoupling connectivity verification from primary command execution.

The server periodically transmits lightweight heartbeat messages to a UDP port dynamically specified by the client 
during the initial handshake. The client, configured in a passive listening mode, awaits these datagrams. Upon receiving
a valid heartbeat, the client updates an internal timestamp reflecting the last confirmed contact with the server. This 
mechanism provides a low-overhead means of monitoring connection health without consuming bandwidth or processing 
resources associated with the primary command flow.

The separation of heartbeat signaling from command traffic simplifies fault detection logic. It allows the system to 
independently assess the viability of the communication path, which is particularly valuable in scenarios where a
TCP connection may remain nominally open but become functionally unresponsive.

## Timeout Handling and Reconnection Logic

Robustness against network instability is achieved through explicit timeout management, which is based on the monitored 
receipt of server heartbeats. The client employs a monotonic time source to track the interval since the last valid 
heartbeat was received on the UDP channel.

If this interval exceeds a predefined threshold, the client interprets the condition as a de facto loss of connectivity 
or server failure. This triggers a deterministic recovery sequence: the existing TCP command channel is terminated, the 
UDP socket is closed, and the client transitions into a reconnection phase. This phase mirrors the initial connection
logic, incorporating retry delays and complete socket reinitialization to ensure a clean state for subsequent attempts.

By anchoring its liveness assessment to the passive reception of heartbeats and enforcing strict temporal boundaries, 
the client avoids indefinite blocking states and ensures eventual reconnection when network conditions permit, without 
relying on unreliable socket-level timeout mechanisms.

## Synchronization and State Monitoring

Internal synchronization within the client is achieved through a centralized event loop that monitors all active 
communication channels. By multiplexing I/O readiness checks and time-based conditions, the client maintains a 
coherent view of its operational state without resorting to concurrent execution models.

State variables track key milestones such as connection establishment, handshake completion, last heartbeat reception,
and overall uptime. These metrics enable the client to make informed decisions about when to continue normal operation
and when to initiate recovery procedures. Periodic status reporting further aids in debugging and experimental 
observation.

## Signal Handling and Process Robustness

Signal handling is implemented conservatively to account for inconsistencies in signal delivery on the target platform.
Only a minimal subset of signals is explicitly handled, primarily to support graceful shutdown or to prevent unintended 
termination due to broken pipes or external kill attempts.

By ignoring or safely handling disruptive signals, the client increases its resilience against both accidental and 
intentional interruptions. This defensive posture ensures that transient anomalies do not permanently disable the 
client, which is essential for long-running experiments.

## Remote Command Execution

Remote command execution is implemented as a direct extension of the TCP command channel. Upon receiving a command 
string, the client invokes it using standard system facilities and captures the resulting output stream. This output 
is transmitted back to the server in real time, preserving the semantics of interactive command execution.

If a command produces no output, the client returns a minimal acknowledgment to confirm successful execution. Error 
conditions are likewise reported explicitly, allowing the server to distinguish between execution failures and 
communication issues.

## File Transfer Management (PUSH)

The server supports the remote deployment of files to clients via a structured `PUSH` command protocol. The transfer
is initiated by the server constructing a header that specifies the target destination path and the total byte length 
of the file. This header is then concatenated with the file's raw binary content.

To maximize the likelihood of coherent delivery and minimize the risk of protocol desynchronization, the server 
transmits the entire data block (header plus content) in a single, continuous write operation using the sendall socket
method. This approach ensures that the data is queued for transmission atomically from the server's application 
perspective, reducing the chance of interleaving with other messages. The server logs the transfer initiation for
verification, relying on the client's complementary reception routine to correctly parse the `PUSH` structure, validate
the payload length, and write the data to the specified filesystem location.

## Connection Integrity Control

Connection integrity within the botnet architecture is maintained through continuous, time-based validation of the 
secondary communication channel. The client's primary mechanism for integrity control is the passive monitoring of 
periodic UDP heartbeat messages transmitted by the server.

By correlating the arrival timestamps of these heartbeats with a monotonic clock, the client can determine whether 
the communication link remains functionally alive. This method effectively addresses common failure modes in embedded
networking, such as half-open TCP connections or silently dropped packets, which might otherwise go undetected.

All incoming data on both the TCP and UDP channels is validated against expected protocol formats. Messages that do not 
conform to the anticipated structure or that originate from unverified sources are silently discarded. This prevents
accidental desynchronization and ensures that the client's operational state transitions are driven solely by verified
and timely communication from the legitimate C2 server.

## Prevention of Deadlocks and Socket Desynchronization

Preventing deadlocks and socket desynchronization is a central concern in long-lived embedded network clients, 
particularly in environments characterized by unreliable kernel behavior and limited libc support. The client 
implementation addresses these risks through explicit control of blocking behavior and conservative socket lifecycle 
management.

All network I/O is mediated through multiplexing mechanisms that ensure the client never blocks indefinitely on a single
socket operation. By consolidating read readiness checks and timeout evaluation within a unified event loop, the client
avoids situations in which one stalled communication channel can halt overall execution.

Special attention is given to scenarios involving partial protocol exchanges, such as interrupted file transfers or 
truncated command messages. In these cases, the client explicitly drains residual data from the socket before resuming
normal operation. This cleanup step prevents protocol misalignment, where leftover bytes from a failed operation could
be misinterpreted as a new command or control message.

When unrecoverable inconsistencies are detected, the client favors full connection teardown over incremental recovery. 
Although this approach incurs a reconnection cost, it ensures that subsequent communication begins from a well-defined 
and synchronized state, which is essential for maintaining correctness in constrained environments.

## Integration of the Client into the Firmware

Integration of the botnet client into the target system is performed at the firmware level rather than through
post-deployment modification. The client binary and its associated components are placed into appropriate directories 
within the firmware root filesystem, ensuring they are available to the system immediately upon boot.

This integration process is intentionally minimal and relies on standard filesystem placement and initialization 
mechanisms provided by the firmware. Where ambiguity arises, the procedure follows the same methodology described
in the firmware repackaging guide developed as part of this research, ensuring consistency and reproducibility across 
experiments.

By embedding the client directly into the firmware image, the resulting system reflects a realistic threat model in 
which malicious functionality is indistinguishable from legitimate system components at runtime.

## Automatic Startup via the Init System

Automatic execution of the botnet components is achieved through integration with the system’s init infrastructure. 
The modified init configuration ensures that the client is launched during the system initialization phase, 
before interactive services become available.

This approach guarantees that the botnet client is activated on every boot cycle without requiring user interaction 
or additional triggers. Startup sequencing is carefully arranged to allow basic system services and networking 
components to initialize before the client attempts to establish outbound connectivity, reducing the likelihood of 
transient startup failures.

The use of standard init mechanisms aligns the client’s behavior with that of legitimate background services, 
reinforcing persistence while maintaining operational stability.

## Cross-Architecture Compilation of the Client

Due to the architectural mismatch between development systems and the target hardware, the client must be compiled 
using a cross-compilation toolchain compatible with the MIPS architecture and the uClibc runtime. This process ensures 
that the generated binary adheres to the instruction set, ABI, and library constraints of the embedded platform.

Rather than embedding compilation details directly into this section, the procedure follows the [cross-compilation 
methodology](Firmware-mod.md) outlined in the toolchain setup of the linked document.
## Insertion into the Root Filesystem

Once compiled, the client binary is inserted into the firmware’s root filesystem at a location consistent with other
system executables. File permissions and ownership are preserved to ensure correct execution semantics at runtime.

The root filesystem is treated as a static deployment artifact, and no dynamic installation steps are required on the 
running system. This approach minimizes runtime complexity and reduces the likelihood of deployment-related errors, 
which are particularly difficult to diagnose on embedded devices.

## Rebuilding the Modified Firmware

After all modifications have been applied, the firmware image is reconstructed using the same tooling and workflow 
described in the [firmware modification guide](Firmware-mod.md). This rebuilding phase consolidates the modified root filesystem and 
original firmware components into a flashable image suitable for deployment on the target device.

Reconstruction is treated as a deterministic process, allowing multiple iterations of experimentation without 
introducing variability between builds. This consistency is essential for controlled analysis and repeatable testing.

## C2 Server Architecture

The Command-and-Control (C2) server acts as the central coordinating entity of the botnet architecture, serving as the 
logical control point through which all client interactions are mediated. Its primary responsibility is to maintain a 
global and coherent view of the botnet, enabling controlled communication, command dissemination, and monitoring of 
connected nodes.

From an architectural standpoint, the server can be conceptually divided into three main layers. The first layer is the
**network core**, which is responsible for accepting incoming connections, managing sockets, and handling low-level 
communication primitives. This layer abstracts the complexities of concurrent network I/O and ensures that multiple 
clients can be served simultaneously without blocking the overall system.

The second layer focuses on **client state management**. It maintains structured representations of connected clients, 
tracking attributes such as unique identifiers, network endpoints, activity status, and timing information.
This stateful approach allows the server to distinguish between newly connected clients, reconnecting nodes, and 
inactive or unreachable ones, thereby enabling consistent lifecycle management across extended periods of operation.

The third layer is the **interaction layer**, which exposes the server’s functionality to the operator through user 
interfaces. This layer decouples the core server logic from human interaction mechanisms, allowing different 
interfaces, such as a basic console or a more advanced textual user interface (TUI), to be employed without altering
the underlying control logic. This separation enhances flexibility and reinforces the server’s role as a reusable and 
extensible research platform.

## Modular Structure of the Server

The server implementation follows a modular design, with functionality distributed across clearly defined components,
notably `server_core`, `ui`, and `models`. This structural organization reflects a deliberate separation of 
responsibilities, aimed at improving code clarity, maintainability, and extensibility.

The `server_core` module encapsulates the fundamental logic of the C2 server, including connection handling, command
dispatching, heartbeat management, and logging. By isolating these mechanisms from presentation concerns, the core 
remains focused on correctness and robustness, independent of how the server is operated or observed.

The `models` module provides structured abstractions for domain entities, most notably the client representation. 
Encapsulating client-related state and behavior within dedicated objects simplifies synchronization, enforces 
consistency, and reduces the risk of duplicated or inconsistent logic across the codebase.

Finally, the `ui` module implements the interaction layer, offering alternative interfaces for server control and
monitoring. This modular separation allows the user interface to evolve independently of the networking and control
logic, facilitating experimentation with different interaction paradigms while preserving a stable backend. 
Overall, this modular architecture aligns with established software engineering principles and supports the long-term 
maintainability of the system.

## Server Startup and User Interface Selection

The server startup procedure is designed to be flexible and operator-friendly, allowing the selection of different 
interaction modes at launch time. This behavior is implemented through command-line argument parsing, enabling runtime 
configuration without modifying the source code.

At startup, the main entry point initializes the core server instance and evaluates user-specified parameters to 
determine which interface should be instantiated. The operator can choose between a simple console-based interface and 
a more advanced textual user interface (TUI). This selection mechanism reflects the separation between control logic and 
presentation, ensuring that the same server functionality is exposed regardless of the chosen interface.

The default use of the TUI underscores its suitability for active operational management, particularly in scenarios
involving multiple simultaneous clients. By making the interface choice explicit and configurable, the system 
accommodates both minimalistic usage, useful for debugging or automation, and richer interactive control, which is 
advantageous during live observation and experimentation.

## Textual User Interface (TUI) for Operational Management

The adoption of a Textual User Interface (TUI) represents a deliberate design choice aimed at improving usability and 
situational awareness during botnet operation and analysis. Unlike a traditional command-line interface, which typically 
interleaves commands and output in a linear stream, the TUI provides a structured and persistent view of the system’s state.

The interface is designed to clearly separate logs, command input, and client status information. This separation allows
the operator to issue commands while simultaneously monitoring responses and observing changes in client connectivity, 
without losing contextual information. Such an arrangement is particularly valuable when managing multiple clients 
concurrently, as it reduces cognitive load and minimizes operator error.

From a research perspective, the TUI constitutes a non-trivial contribution. Many botnet implementations rely on 
rudimentary command-line shells or ad-hoc interaction mechanisms, which scale poorly and offer limited visibility 
into system dynamics. In contrast, the TUI adopted here transforms the C2 server into an interactive control console,
facilitating real-time experimentation, debugging, and observation. This enhanced operability supports more systematic 
analysis and reinforces the server’s role as a controlled experimental platform rather than a purely covert control 
mechanism.

## Management of Incoming Connections

The management of incoming connections is handled through a dedicated acceptance loop that continuously listens for new 
client connections on the server’s command socket. This mechanism is implemented as a blocking accept cycle that 
operates independently of the main control flow, ensuring that the server remains responsive to both network events and 
operator interaction.

Upon accepting a new connection, the server immediately delegates further handling to a dedicated thread. This 
**thread-per-connection** model allows each client to be processed independently, preventing slow or unresponsive clients
from impacting the overall availability of the server. By spawning a separate execution context for each connection, 
the server can concurrently manage multiple clients while preserving a simple and predictable control structure.

The underlying communication channel for this interaction is a TCP socket, which serves as the primary command channel 
between the server and each client. TCP is chosen for its reliability and in-order delivery guarantees, which are 
essential for correct command execution and response handling. This socket remains associated with the client for the 
duration of its active session, forming the backbone of all command-and-control exchanges.

Overall, this design balances concurrency and simplicity, providing sufficient scalability for experimental deployments
while maintaining a clear and debuggable connection management strategy.

## Server Concurrency Model

The server adopts an explicit concurrency model based on native threading, using lightweight threads to isolate client 
handling, background services, and user interaction. Each major functional component,such as client acceptance, 
heartbeat transmission, and individual client communication, executes within its own thread, enabling parallel progress 
without relying on complex asynchronous frameworks.

The choice to avoid asynchronous or event-driven I/O frameworks is deliberate. While asynchronous models can offer 
superior scalability in high-load scenarios, they introduce additional complexity and reduce transparency, particularly
in research-oriented codebases. A thread-based model, by contrast, closely mirrors the conceptual structure of the system 
and simplifies reasoning about execution flow, timing, and failure modes.

To ensure correctness in a concurrent environment, the server employs explicit locking mechanisms. A global lock protects
shared data structures, most notably the collection of connected clients, preventing race conditions during insertion,
removal, or iteration. In addition, each client object maintains its own lock, which serializes access to per-client 
state such as socket operations, activity flags, and timing information.

This hierarchical locking strategy minimizes contention while preventing shared-state corruption. By carefully delimiting 
the scope of each lock and avoiding nested or long-held locks where possible, the implementation reduces the risk of 
deadlocks and maintains consistent internal state even under concurrent access patterns.

## Client Lifecycle on the Server Side

The server-side lifecycle of a client is governed by a well-defined state machine, initiated by the connection handshake and concluding with disconnection. This lifecycle is managed within dedicated client-handling routines that encapsulate all protocol interactions.

Upon accepting a new TCP connection, the server immediately invokes the handshake protocol. The server awaits an identification message conforming to the predefined HELLO| format. This message is parsed to extract the client's unique identifier and auxiliary parameters. A critical function of this handshake is duplicate identifier resolution. The server checks its registry: if the identifier belongs to an already ACTIVE client, the new connection is rejected to prevent session conflict. If the identifier matches an INACTIVE (disconnected) client record, the connection is treated as a reconnection; the existing record is updated with the new socket and network parameters, preserving logical continuity.

Following a successful handshake (or reconnection update), the client is marked as ACTIVE. The server initializes activity timestamps and enables bidirectional command exchange over the TCP channel. The client remains in this state, with timestamps refreshed by command and heartbeat activity, until a disconnection event is detected. This integrated handshake-and-state model ensures that the server maintains a consistent, non-conflicting view of the botnet, effectively linking protocol logic to client lifecycle management.

## Server-Side Handshake Protocol

The server-side handshake protocol complements the client-side initialization procedure and serves as the foundation 
for secure and consistent client registration. Upon accepting a new TCP connection, the server immediately awaits an 
identification message conforming to a predefined textual format, identified by the `HELLO|` prefix. This explicit 
marker allows the server to distinguish valid protocol participants from unintended or malformed connections at an 
early stage.

Once received, the handshake message is parsed to extract essential client attributes, including hostname information 
and a unique client identifier. The server performs basic validation checks on the identifier, most notably verifying 
its expected length and structure. These checks are intended to prevent accidental collisions, malformed registrations,
and trivial protocol misuse within the controlled research environment.

A critical aspect of the handshake process is the handling of duplicate identifiers. If an incoming connection presents
an identifier already known to the server, the server distinguishes between active and inactive instances of that 
client. Active duplicates are rejected to preserve session consistency, while inactive instances are treated as 
legitimate reconnections. In the latter case, the existing client record is updated with the new socket and network 
parameters, allowing continuity of identity across transient disconnections.

Through this mechanism, the handshake protocol establishes a stable mapping between logical client identities and 
physical network connections, ensuring that the server maintains a coherent and up-to-date view of the botnet.

## Client State Management and Tracking

The server maintains a centralized representation of the botnet through an internal data structure that maps unique
client identifiers to client state objects. This structure serves as the authoritative source of truth regarding the
current and historical status of all known clients.

Each client record stores temporal metadata such as the time of first observation (`first_seen`) and the most recent
activity timestamp (`last_seen`). These values enable the server to assess client responsiveness, detect prolonged 
inactivity, and infer connectivity patterns over time. By updating activity timestamps on both command and heartbeat 
interactions, the server ensures that its view of client availability reflects actual network behavior.

In addition to temporal data, the server tracks network-specific attributes, including the client’s IP address, 
command socket parameters, and the UDP port designated for heartbeat communication. The explicit inclusion of the 
heartbeat port allows the server to decouple control and monitoring channels, enhancing flexibility and resilience.

Collectively, these tracked attributes form a dynamic, stateful representation of the botnet from the server’s 
perspective. Rather than treating clients as ephemeral connections, the server models them as persistent entities 
with evolving state, which is essential for systematic monitoring and long-term experimentation.

## Server-Side TCP Command Channel

The TCP command channel constitutes the primary mechanism through which the server exercises control over connected
clients. Once a client has completed the handshake and entered the active state, this channel is used for both command 
transmission and result collection.

The server supports multiple command dissemination modes. Commands may be directed to a specific client, identified by
a prefix of its unique identifier, or broadcast to all currently active clients. This dual-mode capability enables both
targeted experimentation and synchronized actions across the botnet.

Client responses are received asynchronously over the same TCP connection. Upon receipt, the server decodes and 
processes the output, formatting it into a structured representation suitable for presentation within the user 
interface. This formatting step enhances readability and contextualization, associating each response with its 
originating client and network identity.

All command interactions and responses are routed through a centralized logging mechanism, ensuring consistent 
recording and display regardless of the active user interface. This design not only simplifies debugging but also 
supports systematic observation and analysis of client behavior, reinforcing the server’s role as an experimental
control platform rather than a purely command-driven tool.


## Server-Side UDP Heartbeat Mechanism

The server implements a dedicated thread responsible for the periodic dissemination of heartbeat messages over UDP.
This mechanism operates independently of the TCP command channel, providing a lightweight and non-blocking method for
monitoring client availability. By sending heartbeats at a fixed interval, defined by the `heartbeat_interval` parameter,
the server can continuously assess the responsiveness of each connected client.

Each heartbeat message includes minimal identifying information and is sent to the UDP port specified by the client 
during the handshake. Upon successful transmission, the server updates the client’s internal state, marking the latest 
interaction timestamp (`last_seen`). Conversely, the absence of expected heartbeat responses over multiple intervals 
allows the server to detect unresponsive clients and flag them as inactive.

This approach provides robust client liveness detection without interfering with command execution, enabling the server 
to maintain an up-to-date and accurate view of the botnet’s operational state. Clients that consistently fail 
to respond may subsequently be closed or marked for reconnection, ensuring the overall health of the network.


## Timeout Policies and Client Retention

To manage client lifecycle and network stability, the server employs a combination of heartbeat monitoring and retention
policies. Each client is tracked according to its most recent activity, as indicated by the `last_seen` timestamp, and 
is evaluated against the configured `client_retention` interval. Clients that have not communicated within this retention
period are considered inactive or “dead,” and their state is updated accordingly.

Timeout decisions are governed by the heartbeat schedule: if the elapsed time since the last heartbeat exceeds the 
threshold defined by `heartbeat_interval` multiplied by a tolerance factor, the server may initiate a cleanup procedure. 
This includes deactivating the client, closing its sockets, and freeing associated resources. By enforcing these 
policies, the server mitigates resource leakage and prevents stale or phantom clients from affecting the operational 
integrity of the botnet.

This design allows the server to differentiate between temporary network disruptions and persistent failures, 
maintaining an accurate representation of the active client population while minimizing false positives.


## Server-Side File Transfer Management

The server supports remote file deployment to clients via a structured `PUSH` message protocol. Each transfer begins 
with the construction of a header specifying the target destination path and the total byte length of the file. This 
header is concatenated with the file’s raw content and transmitted atomically using `sendall` over the client’s 
established TCP command channel.

Atomic transmission ensures that the client receives the file in its entirety, preventing partial writes or protocol 
desynchronization. The server logs both the header and the initial portion of the payload to facilitate verification 
and troubleshooting, while assuming that the client implements a complementary reception routine capable of interpreting
the `PUSH` structure and writing the file to the specified location.

This approach abstracts the file transfer process from the underlying operating system and network idiosyncrasies, 
relying on the reliability of TCP and client-side correctness. By integrating file transfer into the command channel,
the server maintains a unified communication interface, simplifying client management and enhancing the experimenter’s 
control over distributed deployments.


## Centralized Logging and Decoupling from the UI

The server architecture incorporates a centralized logging system implemented via an asynchronous queue, as realized in
the `Logger` class. This design decouples the generation of log messages from their eventual display, ensuring that core 
server operations, such as client handling, heartbeats, and file transfers, are not blocked or delayed by user interface 
operations.

By maintaining this separation, the server can support multiple UI implementations concurrently, including a traditional 
console interface and a more sophisticated text-based user interface (TUI). The queue-based approach guarantees that all
messages are reliably captured and processed in order, while the UI consumes them independently at its own pace. This
design contributes significantly to maintainability, testability, and extensibility, allowing new visualizations or 
remote monitoring components to be integrated without modifying the core networking or client management logic.


## Server Robustness and Error Handling

Robustness is a key design principle of the server. Throughout the codebase, careful attention is given to exception 
handling, socket timeouts, and resource cleanup. Each client interaction is wrapped in try-except blocks to prevent a 
single malfunctioning client from affecting the stability of the server or other clients. Socket operations are equipped
with explicit timeouts, allowing the server to detect stalled connections and proceed without blocking indefinitely.

Threads responsible for client handling, heartbeats, and logging are configured as daemon threads, ensuring that 
background operations do not prevent graceful shutdowns. In the event of unexpected errors, resources such as sockets,
file descriptors, and client objects are reliably closed or marked inactive, avoiding resource leaks and ensuring that
the server maintains a consistent operational state over prolonged execution. This combination of defensive programming, 
structured exception handling, and controlled cleanup significantly enhances the resilience of the server against both 
network anomalies and software faults.


## Server Scalability Considerations

The server employs a thread-per-connection model to handle client interactions. While this approach provides simplicity 
and direct isolation between client sessions, it introduces potential scalability limitations. Each active client
consumes a separate thread and associated system resources, which can become a bottleneck when the number of concurrent
clients grows significantly.

Moreover, idle or unresponsive clients continue to hold threads and memory, potentially reducing overall throughput. To 
mitigate this, the server incorporates heartbeat monitoring and client retention policies, enabling the identification 
and cleanup of inactive clients. Despite these measures, the thread-based design is most suitable for small to 
medium-sized deployments. For scenarios involving hundreds or thousands of clients, alternative concurrency models, 
such as asynchronous I/O or a thread pool with connection multiplexing, may be required to maintain performance and 
responsiveness.

By combining careful resource management with heartbeat-based cleanup and controlled logging, the server achieves a
balance between operational simplicity and reasonable scalability for the experimental botnet environment.


## Server Security Assumptions

From a research perspective, several explicit assumptions were made regarding the security model of the C2 server. 
First, the system does not implement strong authentication; it relies solely on the uniqueness and integrity of the 
client ID to distinguish between nodes. There is no encryption applied to either command or heartbeat communications, 
which exposes the traffic to potential interception or manipulation.

These design choices are deliberate and justified by the academic context of the project: the primary goal is to study
botnet dynamics, client-server coordination, and fault-tolerant embedded deployment, rather than to build a 
production-grade secure infrastructure. By explicitly stating these assumptions, the experimental environment maintains
clarity regarding the limitations and controlled scope of the research, while allowing focus on the architectural and 
operational aspects of the system.


## Integration Between C2 Server and Embedded Clients

The design of the C2 server and its embedded clients was approached as a unified system rather than as separate 
components. Several aspects of the protocol were co-developed to ensure reliable coordination and robustness:

* **Protocol alignment:** The handshake, command transmission, and PUSH file mechanisms were carefully defined to be mutually compatible, guaranteeing that clients correctly interpret commands and that the server can parse client responses consistently.
* **Heartbeat monitoring:** The periodic UDP heartbeat was designed to provide a continuous measure of client liveness. Its timing, non-blocking implementation on the client, and reception on the server were tuned together to ensure accurate detection of inactive or disconnected nodes.
* **Error handling synchronization:** Both client and server implement robust error handling to recover from network interruptions, socket timeouts, or malformed messages. The server can safely mark clients as inactive and allow reconnection, while clients autonomously attempt reconnection and resend incomplete transfers.

This integration highlights that reliability and maintainability of the botnet were achieved through joint consideration
of client and server behavior. By designing these mechanisms in concert, the system achieves predictable operational 
behavior, simplifies debugging, and allows the research focus to remain on the interplay between embedded device 
constraints and network orchestration.


## Distribution and Activation of the Botnet

From a theoretical standpoint, distribution of a modified firmware image could occur through a variety of channels, 
including social engineering techniques or compromise of firmware distribution infrastructure. However, within the 
scope of this research, no attempt was made to identify or exploit vulnerabilities in the router’s management interface
or update mechanisms.

The discussion of distribution methods remains intentionally high-level and speculative, serving only to contextualize
how such a system might be deployed in real-world scenarios. All experimental activity was confined to controlled
environments and researcher-owned hardware.

## Considerations on Scalability and Stability

The implemented architecture demonstrates functional scalability within the intentional constraints of a centralized, research-oriented C2 model. The clear separation of concerns-client identity management, command channels, and heartbeat monitoring-provides a structured foundation that can conceptually accommodate multiple concurrent clients.

However, as analyzed in the server scalability considerations, this centralized design introduces inherent practical limits. The server's thread-per-connection model and the finite availability of system resources (CPU, memory, network bandwidth) constitute a bottleneck, bounding the number of clients that can be managed simultaneously without performance degradation. The server represents a single point of failure; its unavailability immediately incapacitates the entire network.

Therefore, while the architecture achieves a balance of robustness and simplicity suitable for academic experimentation-featuring resilient clients and a coherent control plane-its scalability is intentionally bounded. This design trade-off prioritizes transparency, debuggability, and controlled analysis over the high-scale, fault-tolerant characteristics required for larger, production-grade distributed systems.

## Limitations of the Implementation

Despite achieving the intended research objectives, the implemented system exhibits several inherent limitations that 
should be acknowledged. These limitations stem both from deliberate design choices and from the constraints imposed by
the target environment.

First, the centralized command-and-control architecture represents a structural limitation in terms of fault tolerance. 
The reliance on a single server introduces a clear single point of failure; any disruption to the C2 server, whether
due to network issues, resource exhaustion, or intentional shutdown, immediately impacts the entire botnet. While 
this choice simplifies analysis and implementation, it limits resilience compared to decentralized or peer-to-peer models.

Second, the communication protocol prioritizes simplicity over robustness and security. Messages are transmitted in 
plaintext, and no cryptographic mechanisms are employed for authentication, confidentiality, or integrity verification.
While this is acceptable and even desirable in a controlled academic setting, it would render the system vulnerable to 
interception, impersonation, or disruption in real-world deployments.

Resource utilization on the client side also imposes practical limits. Although the implementation is designed to be 
lightweight, long-lived connections, repeated reconnection attempts, and command execution can still impact performance
on devices with extremely limited CPU and memory resources. Under large-scale deployment scenarios, these effects could 
become more pronounced.

Finally, the implementation has been validated on a narrow set of hardware and firmware configurations. Differences in 
kernel versions, libc implementations, or vendor-specific modifications could introduce behavioral variations not
covered by this study. As such, generalization beyond the tested platform should be approached with caution.

## Ethical and Research Considerations

The development and analysis of botnet-like systems raise important ethical considerations, which must be explicitly 
addressed. This work was conducted exclusively within an academic research context, using researcher-owned hardware 
and isolated test environments. No third-party devices, networks, or services were involved at any stage of the 
experimentation.

The purpose of this research is not to promote malicious activity, but rather to deepen understanding of how embedded
devices can be abused in real-world attacks. By reconstructing simplified versions of known threat models, researchers 
and defenders can better analyze attack surfaces, identify systemic weaknesses, and develop more effective mitigation 
strategies.

All design decisions were guided by the principles of responsible disclosure and defensive research. The system 
intentionally omits features that would increase stealth, persistence against removal, or large-scale abuse. 
Furthermore, the documentation emphasizes transparency and reproducibility, enabling peer review and informed 
discussion rather than covert exploitation.

In this sense, the work aligns with established practices in security research, where controlled experimentation 
with potentially harmful techniques is justified by the broader goal of improving system security and resilience.

## Summary of the Overall Operational Flow

In summary, the implemented system follows a clear and deterministic operational flow that integrates firmware 
modification, embedded client execution, and centralized control.

The process begins with the integration of custom binaries into the firmware image and the modification of the system
initialization sequence to ensure automatic execution at boot. Once the device starts, the client daemon initializes,
waits for basic network availability, and attempts to establish outbound communication with the command-and-control 
server.

Upon successful connection, an initial handshake synchronizes state between client and server, after which the client
enters its main operational loop. In this phase, it listens for commands over a persistent TCP channel, executes 
received instructions, and returns results to the server. In parallel, a secondary UDP channel is used to monitor 
connectivity through periodic heartbeat messages.

Timeout detection, reconnection logic, and conservative error handling ensure that the client can recover from 
transient failures without manual intervention. This cycle continues for the lifetime of the device, providing a stable
and observable platform for studying embedded command-and-control behavior.

Overall, the system demonstrates how relatively simple components, when integrated at the firmware level, can produce
complex and long-lived behavior in resource-constrained environments. This reinforces the importance of secure firmware 
design and highlights the need for continued research into embedded system security.

